{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling:\n",
    "\n",
    "What is feature scaling? Feature scaling is a way of transforming your data into a common range of values. There are two common scalings:\n",
    "\n",
    "1) Standardizing         \n",
    "2) Normalizing\n",
    "\n",
    "## Standardizing:\n",
    "\n",
    "**Standardizing** is completed by taking each value of your column, subtracting the mean of the column, and then dividing by the standard deviation of the column. In Python, let's say you have a column in df called height. You could create a standardized height as:\n",
    "\n",
    "**df[\"height_standard\"] = (df[\"height\"] - df[\"height\"].mean()) / df[\"height\"].std()**\n",
    "\n",
    "This will create a new \"standardized\" column where each value is a comparison to the mean of the column, and a new, standardized value can be interpreted as the number of standard deviations the original height was from the mean. This type of feature scaling is by far the most common of all techniques (for the reasons discussed here, but also likely because of precedent).\n",
    "\n",
    "## Normalizing:\n",
    "A second type of feature scaling that is very popular is known as normalizing. With normalizing, data are scaled between 0 and 1. Using the same example as above, we could perform normalizing in python in the following way:\n",
    "\n",
    "**df[\"height_normal\"] = (df[\"height\"] - df[\"height\"].min()) /     \\\n",
    "                      (df[\"height\"].max() - df['height'].min())**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient  :\n",
      " [  0.           3.90753617   9.02575748  -0.         -11.78303187\n",
      "   0.45340137]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Add import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import lasso for Regularization and StandardScaler for Scaling data\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assign the data to predictor and outcome variables\n",
    "# TODO: Load the data\n",
    "train_data = pd.read_csv('data_StandardScaling.csv', header = None)\n",
    "X = train_data.iloc[:,:-1]\n",
    "y = train_data.iloc[:,-1]\n",
    "\n",
    "# TODO: Create the standardization scaling object.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# TODO: Fit the standardization parameters and scale the data.\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# TODO: Create the linear regression model with lasso regularization.\n",
    "lasso_reg = Lasso()\n",
    "\n",
    "# TODO: Fit the model.\n",
    "lasso_reg.fit(X_scaled, y)\n",
    "\n",
    "# TODO: Retrieve and print out the coefficients from the regression model.\n",
    "reg_coef = lasso_reg.coef_\n",
    "print('Coefficient  :\\n', reg_coef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
